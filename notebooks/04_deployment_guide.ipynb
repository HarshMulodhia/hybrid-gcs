{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Deployment Guide\n",
    "\n",
    "Complete guide for deploying Hybrid-GCS in production.\n",
    "\n",
    "**Topics:**\n",
    "- Model serialization\n",
    "- Hardware integration\n",
    "- Real-time execution\n",
    "- Safety considerations\n",
    "- Monitoring & logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from hybrid_gcs.core import GCSDecomposer\n",
    "from hybrid_gcs.integration import HybridPolicy, HybridPolicyConfig\n",
    "from hybrid_gcs.utils import ConfigManager\n",
    "\n",
    "# Setup deployment directory\n",
    "deploy_dir = Path('deployment')\n",
    "deploy_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"âœ… Deployment directory ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deployment config\n",
    "deployment_config = {\n",
    "    'version': '2.0.0',\n",
    "    'model_type': 'hybrid_gcs',\n",
    "    'hybrid_config': {\n",
    "        'blend_method': 'weighted',\n",
    "        'gcs_weight': 0.5,\n",
    "        'rl_weight': 0.5,\n",
    "        'planning_horizon': 10,\n",
    "        'safety_margin': 0.1,\n",
    "    },\n",
    "    'hardware': {\n",
    "        'type': 'real_robot',\n",
    "        'max_frequency': 100,  # Hz\n",
    "        'control_mode': 'velocity',\n",
    "    },\n",
    "    'safety': {\n",
    "        'enable_emergency_stop': True,\n",
    "        'enable_collision_detection': True,\n",
    "        'velocity_limit': 0.5,\n",
    "        'acceleration_limit': 1.0,\n",
    "    },\n",
    "    'logging': {\n",
    "        'level': 'INFO',\n",
    "        'enable_file_logging': True,\n",
    "        'log_frequency': 10,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save config\n",
    "with open(deploy_dir / 'config.json', 'w') as f:\n",
    "    json.dump(deployment_config, f, indent=2)\n",
    "\n",
    "print(\"âœ… Deployment config saved\")\n",
    "print(json.dumps(deployment_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Real-time Execution Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time control template\n",
    "template = \"\"\"\n# Real-time Control Loop Template\n# Place in deployment/control_loop.py\n\nimport numpy as np\nimport time\nimport logging\nfrom hybrid_gcs.integration import HybridPolicy, HybridPolicyConfig\nfrom hybrid_gcs.utils import ConfigManager\n\nclass RealTimeController:\n    def __init__(self, config_path='config.json', log_path='logs'):\n        self.config = ConfigManager(config_path)\n        self.logger = logging.getLogger(__name__)\n        \n        # Initialize policy\n        hybrid_config = HybridPolicyConfig(**self.config.get('hybrid_config'))\n        self.policy = HybridPolicy(decomposer, rl_policy, hybrid_config)\n        \n        # Hardware interface\n        self.robot = self._init_hardware()\n        \n    def _init_hardware(self):\n        \"\"\"Initialize robot hardware.\"\"\"\n        # TODO: Initialize actual hardware\n        pass\n    \n    def run(self, target_frequency=100):\n        \"\"\"Main control loop.\"\"\"\n        period = 1.0 / target_frequency\n        state_history = []\n        \n        while True:\n            start_time = time.time()\n            \n            # 1. Get state from sensors\n            state = self.robot.get_state()\n            state_history.append(state)\n            \n            # 2. Compute action\n            try:\n                action = self.policy.compute_action(state, self.goal)\n            except Exception as e:\n                self.logger.error(f\"Policy error: {e}\")\n                action = np.zeros(6)  # Safe fallback\n            \n            # 3. Apply safety limits\n            action = self._apply_safety_limits(action)\n            \n            # 4. Send to robot\n            self.robot.apply_action(action)\n            \n            # 5. Logging (sparse to avoid overhead)\n            if len(state_history) % 10 == 0:\n                self.logger.info(f\"State: {state}, Action: {action}\")\n            \n            # 6. Maintain frequency\n            elapsed = time.time() - start_time\n            if elapsed < period:\n                time.sleep(period - elapsed)\n    \n    def _apply_safety_limits(self, action):\n        \"\"\"Apply safety constraints.\"\"\"\n        config = self.config.get('safety')\n        \n        # Velocity limits\n        action = np.clip(action, -config['velocity_limit'], config['velocity_limit'])\n        \n        return action\n    \n    def stop(self):\n        \"\"\"Stop controller and cleanup.\"\"\"\n        self.robot.stop()\n        self.logger.info(\"Controller stopped\")\n\"\"\"\n\n# Save template\nwith open(deploy_dir / 'control_loop_template.py', 'w') as f:\n    f.write(template)\n\nprint(\"âœ… Real-time control loop template saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Safety Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_checklist = {\n",
    "    'Pre-Deployment': [\n",
    "        'âœ“ Model trained and validated',\n",
    "        'âœ“ Safety limits configured',\n",
    "        'âœ“ Emergency stop tested',\n",
    "        'âœ“ Collision detection enabled',\n",
    "        'âœ“ Hardware calibrated',\n",
    "    ],\n",
    "    'During Operation': [\n",
    "        'âœ“ Real-time monitoring active',\n",
    "        'âœ“ Logging enabled',\n",
    "        'âœ“ Heartbeat signals working',\n",
    "        'âœ“ Safety margins respected',\n",
    "        'âœ“ Velocity limits enforced',\n",
    "    ],\n",
    "    'Post-Operation': [\n",
    "        'âœ“ Logs analyzed',\n",
    "        'âœ“ Performance metrics computed',\n",
    "        'âœ“ Hardware checked',\n",
    "        'âœ“ Model updated if needed',\n",
    "        'âœ“ Incident report (if any)',\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"DEPLOYMENT SAFETY CHECKLIST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for phase, items in safety_checklist.items():\n",
    "    print(f\"\\n{phase}:\")\n",
    "    for item in items:\n",
    "        print(f\"  {item}\")\n",
    "\n",
    "# Save as JSON\n",
    "with open(deploy_dir / 'safety_checklist.json', 'w') as f:\n",
    "    json.dump(safety_checklist, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Checklist saved to {deploy_dir / 'safety_checklist.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monitoring & Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging configuration\n",
    "logging_config = {\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    'formatters': {\n",
    "        'standard': {\n",
    "            'format': '[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s'\n",
    "        },\n",
    "        'detailed': {\n",
    "            'format': '[%(asctime)s] [%(name)s] [%(levelname)s] [%(filename)s:%(lineno)d] %(message)s'\n",
    "        },\n",
    "    },\n",
    "    'handlers': {\n",
    "        'console': {\n",
    "            'class': 'logging.StreamHandler',\n",
    "            'level': 'INFO',\n",
    "            'formatter': 'standard',\n",
    "            'stream': 'ext://sys.stdout'\n",
    "        },\n",
    "        'file': {\n",
    "            'class': 'logging.handlers.RotatingFileHandler',\n",
    "            'level': 'DEBUG',\n",
    "            'formatter': 'detailed',\n",
    "            'filename': 'logs/hybrid_gcs.log',\n",
    "            'maxBytes': 10485760,  # 10MB\n",
    "            'backupCount': 5\n",
    "        },\n",
    "    },\n",
    "    'loggers': {\n",
    "        'hybrid_gcs': {\n",
    "            'level': 'DEBUG',\n",
    "            'handlers': ['console', 'file'],\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save logging config\n",
    "import json\n",
    "with open(deploy_dir / 'logging_config.json', 'w') as f:\n",
    "    json.dump(logging_config, f, indent=2)\n",
    "\n",
    "print(\"âœ… Logging configuration saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics to monitor\n",
    "monitoring_metrics = {\n",
    "    'Real-time Performance': [\n",
    "        'Control loop frequency (Hz)',\n",
    "        'Latency (ms)',\n",
    "        'Policy computation time (ms)',\n",
    "        'Action execution time (ms)',\n",
    "    ],\n",
    "    'Safety Metrics': [\n",
    "        'Min obstacle distance',\n",
    "        'Emergency stops triggered',\n",
    "        'Safety violations',\n",
    "        'Collision events',\n",
    "    ],\n",
    "    'Performance Metrics': [\n",
    "        'Task success rate',\n",
    "        'Average reward',\n",
    "        'Path efficiency',\n",
    "        'Execution time vs expected',\n",
    "    ],\n",
    "    'System Health': [\n",
    "        'CPU usage',\n",
    "        'Memory usage',\n",
    "        'Disk I/O',\n",
    "        'Network latency (if remote)',\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"KEY METRICS TO MONITOR\")\n",
    "print(\"=\" * 50)\n",
    "for category, metrics in monitoring_metrics.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for metric in metrics:\n",
    "        print(f\"  â€¢ {metric}\")\n",
    "\n",
    "# Save metrics definition\n",
    "with open(deploy_dir / 'monitoring_metrics.json', 'w') as f:\n",
    "    json.dump(monitoring_metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Monitoring metrics definition saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deployment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_summary = f\"\"\"\nDEPLOYMENT SUMMARY\n{'='*60}\n\nâœ… Created Files:\n   â€¢ config.json - Deployment configuration\n   â€¢ safety_checklist.json - Safety verification items\n   â€¢ logging_config.json - Logging setup\n   â€¢ monitoring_metrics.json - Performance metrics\n   â€¢ control_loop_template.py - Real-time control template\n\nðŸ“‹ Key Steps:\n   1. Review and customize config.json\n   2. Implement control_loop.py based on template\n   3. Setup hardware interface\n   4. Run safety checklist\n   5. Enable monitoring and logging\n   6. Start deployment\n\nðŸ”’ Safety Features:\n   â€¢ Emergency stop mechanism\n   â€¢ Collision detection\n   â€¢ Velocity/acceleration limits\n   â€¢ Real-time logging\n   â€¢ Health monitoring\n\nðŸ“Š Monitoring:\n   â€¢ Real-time performance metrics\n   â€¢ Safety event logging\n   â€¢ System health tracking\n   â€¢ Performance analysis\n\nðŸš€ Ready for Production!\n\"\"\"\n",
    "\n",
    "print(deployment_summary)\n",
    "\n",
    "# Save summary\n",
    "with open(deploy_dir / 'DEPLOYMENT_SUMMARY.txt', 'w') as f:\n",
    "    f.write(deployment_summary)\n",
    "\n",
    "print(f\"\\nâœ… All deployment files ready in: {deploy_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
