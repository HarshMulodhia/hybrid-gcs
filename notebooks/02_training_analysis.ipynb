{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Training Analysis & Metrics\n",
    "\n",
    "Comprehensive analysis of training performance and metrics.\n",
    "\n",
    "**Topics:**\n",
    "- Training curves and convergence\n",
    "- Reward analysis\n",
    "- Loss tracking\n",
    "- Curriculum learning effects\n",
    "- Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hybrid_gcs.training import OptimizedTrainer\n",
    "from hybrid_gcs.utils import DataBuffer, normalize_data\n",
    "\n",
    "print(\"âœ… Modules loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate training data\n",
    "episodes = 1000\n",
    "episode_rewards = []\n",
    "episode_lengths = []\n",
    "episode_losses = []\n",
    "\n",
    "# Simulate learning curve\n",
    "for episode in range(episodes):\n",
    "    # Reward increases with training (with noise)\n",
    "    base_reward = 100 * (1 - np.exp(-episode / 200))\n",
    "    reward = base_reward + np.random.randn() * 10\n",
    "    episode_rewards.append(reward)\n",
    "    \n",
    "    # Length decreases (more efficient)\n",
    "    base_length = 100 * np.exp(-episode / 300) + 20\n",
    "    length = base_length + np.random.randn() * 5\n",
    "    episode_lengths.append(max(length, 10))\n",
    "    \n",
    "    # Loss decreases\n",
    "    base_loss = 1.0 * np.exp(-episode / 200)\n",
    "    loss = base_loss + np.random.randn() * 0.05\n",
    "    episode_losses.append(max(loss, 0))\n",
    "\n",
    "print(f\"âœ… Generated {episodes} episodes of training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Episode rewards\n",
    "axes[0, 0].plot(episode_rewards, alpha=0.7, linewidth=1)\n",
    "# Moving average\n",
    "window = 50\n",
    "ma_rewards = np.convolve(episode_rewards, np.ones(window)/window, mode='valid')\n",
    "axes[0, 0].plot(range(window-1, episodes), ma_rewards, 'r-', linewidth=2, label=f'MA-{window}')\n",
    "axes[0, 0].set_xlabel('Episode')\n",
    "axes[0, 0].set_ylabel('Reward')\n",
    "axes[0, 0].set_title('Episode Rewards')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Episode lengths\n",
    "axes[0, 1].plot(episode_lengths, alpha=0.7, linewidth=1, color='green')\n",
    "ma_lengths = np.convolve(episode_lengths, np.ones(window)/window, mode='valid')\n",
    "axes[0, 1].plot(range(window-1, episodes), ma_lengths, 'darkgreen', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Episode')\n",
    "axes[0, 1].set_ylabel('Episode Length')\n",
    "axes[0, 1].set_title('Episode Lengths (Lower is Better)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Losses\n",
    "axes[1, 0].plot(episode_losses, alpha=0.7, linewidth=1, color='red')\n",
    "ma_losses = np.convolve(episode_losses, np.ones(window)/window, mode='valid')\n",
    "axes[1, 0].plot(range(window-1, episodes), ma_losses, 'darkred', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Episode')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].set_title('Training Loss')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "# Combined metrics\n",
    "normalized_rewards = (np.array(episode_rewards) - np.min(episode_rewards)) / (np.max(episode_rewards) - np.min(episode_rewards))\n",
    "normalized_lengths = 1 - (np.array(episode_lengths) - np.min(episode_lengths)) / (np.max(episode_lengths) - np.min(episode_lengths))\n",
    "normalized_losses = 1 - (np.array(episode_losses) - np.min(episode_losses)) / (np.max(episode_losses) - np.min(episode_losses))\n",
    "\n",
    "axes[1, 1].plot(normalized_rewards, label='Reward', linewidth=2, alpha=0.7)\n",
    "axes[1, 1].plot(normalized_lengths, label='Efficiency', linewidth=2, alpha=0.7)\n",
    "axes[1, 1].plot(normalized_losses, label='Training', linewidth=2, alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Episode')\n",
    "axes[1, 1].set_ylabel('Normalized Score')\n",
    "axes[1, 1].set_title('Normalized Performance Metrics')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training into quarters\n",
    "quarter_size = len(episode_rewards) // 4\n",
    "\n",
    "quarters = {\n",
    "    'Q1': episode_rewards[:quarter_size],\n",
    "    'Q2': episode_rewards[quarter_size:2*quarter_size],\n",
    "    'Q3': episode_rewards[2*quarter_size:3*quarter_size],\n",
    "    'Q4': episode_rewards[3*quarter_size:],\n",
    "}\n",
    "\n",
    "print(\"Training Progress Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for quarter, rewards in quarters.items():\n",
    "    print(f\"\\n{quarter}:\")\n",
    "    print(f\"  Mean Reward: {np.mean(rewards):.2f}\")\n",
    "    print(f\"  Std Dev: {np.std(rewards):.2f}\")\n",
    "    print(f\"  Min: {np.min(rewards):.2f}\")\n",
    "    print(f\"  Max: {np.max(rewards):.2f}\")\n",
    "    print(f\"  Median: {np.median(rewards):.2f}\")\n",
    "\n",
    "# Improvement\n",
    "improvement = (np.mean(quarters['Q4']) - np.mean(quarters['Q1'])) / np.mean(quarters['Q1']) * 100\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Overall Improvement (Q1 â†’ Q4): {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check convergence\n",
    "window = 100\n",
    "ma_rewards = np.convolve(episode_rewards, np.ones(window)/window, mode='valid')\n",
    "\n",
    "# Compute velocity (rate of change)\n",
    "velocity = np.diff(ma_rewards)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Moving average\n",
    "axes[0].plot(range(window-1, episodes), ma_rewards, linewidth=2)\n",
    "axes[0].axhline(y=np.max(ma_rewards), color='r', linestyle='--', alpha=0.5, label='Peak')\n",
    "axes[0].set_xlabel('Episode')\n",
    "axes[0].set_ylabel('Reward (Moving Avg)')\n",
    "axes[0].set_title(f'Learning Curve (MA-{window})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Velocity\n",
    "axes[1].plot(range(window, episodes), velocity, linewidth=1, alpha=0.7)\n",
    "axes[1].axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "axes[1].set_xlabel('Episode')\n",
    "axes[1].set_ylabel('Reward Change')\n",
    "axes[1].set_title('Convergence Velocity')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final velocity (avg last 50): {np.mean(velocity[-50:]):.4f}\")\n",
    "print(f\"Convergence status: {'Converged' if abs(np.mean(velocity[-50:])) < 0.01 else 'Still improving'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key insights from training analysis:\n",
    "- ðŸ“ˆ Learning curves show consistent improvement\n",
    "- âš¡ Episode efficiency improves over time\n",
    "- ðŸŽ¯ Loss decreases as expected\n",
    "- ðŸ”„ Convergence is progressing well\n",
    "\n",
    "Next: Explore visualization and deployment strategies!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
